# GitLab CI/CD Pipeline for Swarm Works
# Deploys Multi-Agent AI System and Next.js Frontend

stages:
  - build
  - test
  - deploy-ai
  - deploy-frontend

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"
  AI_SERVICE_PORT: "8000"
  FRONTEND_PORT: "3000"

# Build Multi-Agent AI Service Docker Image
build-ai-service:
  stage: build
  image: docker:24.0.5
  services:
    - docker:24.0.5-dind
  variables:
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_VERIFY: 1
    DOCKER_CERT_PATH: "/certs/client"
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - cd deployment
    - |
      cat > Dockerfile << 'EOF'
      FROM ubuntu:22.04

      # Install system dependencies
      RUN apt-get update && apt-get install -y \
          python3 \
          python3-pip \
          python3-venv \
          curl \
          git \
          && rm -rf /var/lib/apt/lists/*

      # Install Ollama
      RUN curl -fsSL https://ollama.ai/install.sh | sh

      # Create app directory
      WORKDIR /app

      # Copy all deployment files
      COPY multi_agent_server.py .
      COPY api_server.py .
      COPY requirements.txt .

      # Install Python dependencies
      RUN pip3 install -r requirements.txt

      # Create models directory
      RUN mkdir -p /root/.ollama/models

      # Expose port
      EXPOSE 8000

      # Start script
      COPY start.sh .
      RUN chmod +x start.sh

      CMD ["./start.sh"]
      EOF
    - |
      cat > requirements.txt << 'EOF'
      fastapi==0.104.1
      uvicorn==0.24.0
      httpx==0.25.2
      pydantic==2.5.0
      psutil==5.9.6
      python-multipart==0.0.6
      asyncio==3.4.3
      logging==0.4.9.6
      EOF
    - |
      # Copy the multi-agent server
      cp multi_agent_server.py .
    - |
      cat > start.sh << 'EOF'
      #!/bin/bash
      
      # Start Ollama in background
      ollama serve &
      
      # Wait for Ollama to start
      echo "Waiting for Ollama to start..."
      sleep 10
      
      # Pull models if not exists
      echo "Checking and pulling models..."
      
      # Pull CodeLlama 7B
      if ! ollama list | grep -q "codellama:7b-instruct"; then
          echo "Downloading CodeLlama 7B..."
          ollama pull codellama:7b-instruct || echo "Failed to pull codellama, continuing..."
      fi
      
      # Pull Mistral 7B
      if ! ollama list | grep -q "mistral:7b-instruct"; then
          echo "Downloading Mistral 7B..."
          ollama pull mistral:7b-instruct || echo "Failed to pull mistral, continuing..."
      fi
      
      # Start the multi-agent API service
      echo "Starting multi-agent server..."
      python3 multi_agent_server.py
      EOF
    - docker build -t $CI_REGISTRY_IMAGE/multi-agent-ai:$CI_COMMIT_SHA .
    - docker push $CI_REGISTRY_IMAGE/multi-agent-ai:$CI_COMMIT_SHA
    - docker tag $CI_REGISTRY_IMAGE/multi-agent-ai:$CI_COMMIT_SHA $CI_REGISTRY_IMAGE/multi-agent-ai:latest
    - docker push $CI_REGISTRY_IMAGE/multi-agent-ai:latest
  only:
    - main
    - develop

# Build Next.js Frontend
build-frontend:
  stage: build
  image: node:18-alpine
  cache:
    key: ${CI_COMMIT_REF_SLUG}
    paths:
      - node_modules/
      - .next/cache/
  script:
    - npm ci --prefer-offline
    - npm run build
  artifacts:
    paths:
      - .next/
      - node_modules/
      - public/
    expire_in: 1 hour
  only:
    - main
    - develop

# Run Tests
test-frontend:
  stage: test
  image: node:18-alpine
  dependencies:
    - build-frontend
  script:
    - npm run type-check
    - npm run lint
  only:
    - main
    - develop

# Deploy Multi-Agent AI Service to DigitalOcean
deploy-ai-digitalocean:
  stage: deploy-ai
  image: alpine:latest
  before_script:
    - apk add --no-cache curl openssh-client
    - eval $(ssh-agent -s)
    - echo "$DO_SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh
    - ssh-keyscan -H $DO_DROPLET_IP >> ~/.ssh/known_hosts
  script:
    - |
      ssh root@$DO_DROPLET_IP << 'ENDSSH'
        # Update system
        apt-get update
        
        # Install Docker if not exists
        if ! command -v docker &> /dev/null; then
            curl -fsSL https://get.docker.com -o get-docker.sh
            sh get-docker.sh
        fi
        
        # Login to GitLab registry
        docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
        
        # Stop existing containers
        docker stop swarm-multi-agent || true
        docker rm swarm-multi-agent || true
        
        # Pull and run new multi-agent image
        docker pull $CI_REGISTRY_IMAGE/multi-agent-ai:latest
        
        # Create volume for model persistence
        docker volume create ollama_models
        
        # Run Multi-Agent AI service container
        docker run -d \
          --name swarm-multi-agent \
          --restart unless-stopped \
          -p 8000:8000 \
          -v ollama_models:/root/.ollama \
          $CI_REGISTRY_IMAGE/multi-agent-ai:latest
        
        # Setup Nginx if not exists
        if ! command -v nginx &> /dev/null; then
            apt-get install -y nginx
        fi
        
        # Configure Nginx
        cat > /etc/nginx/sites-available/swarm-ai << 'EOF'
        server {
            listen 80;
            server_name _;
            
            client_max_body_size 50M;
            
            location / {
                proxy_pass http://localhost:8000;
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_read_timeout 300s;
                proxy_connect_timeout 300s;
                proxy_send_timeout 300s;
            }
            
            location /health {
                proxy_pass http://localhost:8000/health;
                proxy_read_timeout 10s;
            }
        }
      EOF
        
        # Enable the site
        ln -sf /etc/nginx/sites-available/swarm-ai /etc/nginx/sites-enabled/
        rm -f /etc/nginx/sites-enabled/default
        
        # Test and reload Nginx
        nginx -t && systemctl restart nginx
        
        # Wait for service to be ready
        sleep 30
        
        # Check health
        curl -f http://localhost:8000/health || echo "Health check failed but continuing..."
      ENDSSH
  environment:
    name: ai-production
    url: http://$DO_DROPLET_IP
  only:
    - main

# Deploy Frontend to Vercel
deploy-frontend-vercel:
  stage: deploy-frontend
  image: node:18-alpine
  dependencies:
    - build-frontend
  before_script:
    - npm install -g vercel
  script:
    - |
      # Create environment file
      cat > .env.production << EOF
      NEXTAUTH_URL=$VERCEL_URL
      NEXTAUTH_SECRET=$NEXTAUTH_SECRET
      GITHUB_ID=$GITHUB_ID
      GITHUB_SECRET=$GITHUB_SECRET
      ARCADE_AI_API_KEY=$ARCADE_AI_API_KEY
      NEXT_PUBLIC_SUPABASE_URL=$NEXT_PUBLIC_SUPABASE_URL
      NEXT_PUBLIC_SUPABASE_ANON_KEY=$NEXT_PUBLIC_SUPABASE_ANON_KEY
      SUPABASE_SERVICE_ROLE_KEY=$SUPABASE_SERVICE_ROLE_KEY
      DATABASE_URL=$DATABASE_URL
      NEXT_PUBLIC_AI_SERVICE_URL=http://$DO_DROPLET_IP:8000
      AI_SERVICE_API_KEY=$AI_SERVICE_API_KEY
      NEXT_PUBLIC_SOLANA_RPC_URL=$NEXT_PUBLIC_SOLANA_RPC_URL
      NEXT_PUBLIC_MERCHANT_WALLET=$NEXT_PUBLIC_MERCHANT_WALLET
      STRIPE_SECRET_KEY=$STRIPE_SECRET_KEY
      STRIPE_WEBHOOK_SECRET=$STRIPE_WEBHOOK_SECRET
      EOF
    - |
      # Deploy to Vercel
      vercel --token $VERCEL_TOKEN --prod --yes
  environment:
    name: frontend-production
    url: $VERCEL_URL
  only:
    - main

# Alternative: Deploy Frontend to DigitalOcean App Platform
deploy-frontend-do-app:
  stage: deploy-frontend
  image: alpine:latest
  before_script:
    - apk add --no-cache curl jq
  script:
    - |
      # Create app spec
      APP_SPEC=$(cat <<EOF
      {
        "name": "swarm-works-frontend",
        "region": "nyc",
        "services": [
          {
            "name": "web",
            "github": {
              "repo": "$CI_PROJECT_PATH",
              "branch": "main",
              "deploy_on_push": true
            },
            "source_dir": "/nextjs-swarm-works",
            "build_command": "npm ci && npm run build",
            "run_command": "npm start",
            "environment_slug": "node-js",
            "instance_count": 1,
            "instance_size_slug": "basic-xxs",
            "http_port": 3000,
            "routes": [
              {
                "path": "/"
              }
            ],
            "envs": [
              {"key": "NEXTAUTH_URL", "value": "https://swarm-works-frontend.ondigitalocean.app", "type": "GENERAL"},
              {"key": "NEXTAUTH_SECRET", "value": "$NEXTAUTH_SECRET", "type": "SECRET"},
              {"key": "GITHUB_ID", "value": "$GITHUB_ID", "type": "SECRET"},
              {"key": "GITHUB_SECRET", "value": "$GITHUB_SECRET", "type": "SECRET"},
              {"key": "DATABASE_URL", "value": "$DATABASE_URL", "type": "SECRET"},
              {"key": "NEXT_PUBLIC_AI_SERVICE_URL", "value": "http://$DO_DROPLET_IP:8000", "type": "GENERAL"},
              {"key": "NEXT_PUBLIC_SUPABASE_URL", "value": "$NEXT_PUBLIC_SUPABASE_URL", "type": "GENERAL"},
              {"key": "NEXT_PUBLIC_SUPABASE_ANON_KEY", "value": "$NEXT_PUBLIC_SUPABASE_ANON_KEY", "type": "GENERAL"},
              {"key": "SUPABASE_SERVICE_ROLE_KEY", "value": "$SUPABASE_SERVICE_ROLE_KEY", "type": "SECRET"}
            ]
          }
        ]
      }
      EOF
      )
      
      # Create or update app
      curl -X POST "https://api.digitalocean.com/v2/apps" \
        -H "Authorization: Bearer $DO_API_TOKEN" \
        -H "Content-Type: application/json" \
        -d "{\"spec\": $APP_SPEC}"
  when: manual
  only:
    - main